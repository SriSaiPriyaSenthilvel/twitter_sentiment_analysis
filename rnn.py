# -*- coding: utf-8 -*-
"""rnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gqQTCZOp-XZD-VKg7RC6h5N1wybJBLKB
"""

import pandas as pd
import numpy as np
import nltk
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Download NLTK resources
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

# Load datasets
train_df = pd.read_csv('/content/twitter_training.csv', header=None, names=['id', 'entity', 'category', 'clean_text'])
val_df = pd.read_csv('/content/twitter_validation.csv', header=None, names=['id', 'entity', 'category', 'clean_text'])

# Combine and filter
df = pd.concat([train_df, val_df])
df = df[['clean_text', 'category']].dropna()
df = df[df['category'].isin(['Positive', 'Neutral', 'Negative'])]

# Label encoding
label_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}
df['label'] = df['category'].map(label_map)

# Text Preprocessing
import nltk
nltk.download('punkt')
stop_words = set(stopwords.words('english')) - {"not", "no", "nor"}
def preprocess(text):
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    words = word_tokenize(text)
    filtered_words = [word for word in words if word not in stop_words]
    return ' '.join(filtered_words)

df['clean_text'] = df['clean_text'].astype(str).apply(preprocess)

# Tokenization and padding
tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')
tokenizer.fit_on_texts(df['clean_text'])
sequences = tokenizer.texts_to_sequences(df['clean_text'])
X = pad_sequences(sequences, maxlen=60, padding='post', truncating='post')
y = to_categorical(df['label'], num_classes=3)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build RNN model
model = Sequential([
    Embedding(input_dim=5000, output_dim=64, input_length=60),
    SimpleRNN(64),
    Dropout(0.5),
    Dense(3, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))

# Prediction function
def predict_sentiment(text):
    text = preprocess(text)
    seq = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(seq, maxlen=60, padding='post')
    pred = model.predict(padded)
    label = np.argmax(pred)
    return {0: 'Negative', 1: 'Neutral', 2: 'Positive'}[label]

# Interactive input
while True:
    user_input = input("Enter a tweet (or type 'exit'): ")
    if user_input.lower() == 'exit':
        break
    sentiment = predict_sentiment(user_input)
    print(f"Predicted Sentiment: {sentiment}")

!pip install streamlit pyngrok --quiet

import pickle

# Save model
model.save('sentiment_rnn_model.h5')

# Save tokenizer
with open('tokenizer.pickle', 'wb') as handle:
    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('label_map.pickle', 'wb') as handle:
    pickle.dump(label_map, handle, protocol=pickle.HIGHEST_PROTOCOL)

app_code = """
import streamlit as st
import tensorflow as tf
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load trained model and tokenizer
model = tf.keras.models.load_model('sentiment_rnn_model.h5')
with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

# Try loading label encoder
try:
    with open('label_encoder.pickle', 'rb') as handle:
        label_encoder = pickle.load(handle)
    use_label_encoder = True
except:
    use_label_encoder = False

# Set max sequence length (same as training)
MAX_LEN = 200

st.title("Sentiment Analysis with RNN")
st.subheader("Enter text below to get sentiment prediction:")

user_input = st.text_area("Your Input:")

if st.button("Predict Sentiment"):
    if user_input.strip() == "":
        st.warning("Please enter some text.")
    else:
        sequence = tokenizer.texts_to_sequences([user_input])
        padded = pad_sequences(sequence, maxlen=MAX_LEN)
        prediction = model.predict(padded)[0]
        sentiment_class = prediction.argmax()

        if use_label_encoder:
            sentiment = label_encoder.inverse_transform([sentiment_class])[0]
        else:
            sentiment = ["Negative", "Neutral", "Positive"][sentiment_class]

        st.success(f"Predicted Sentiment: {sentiment}")
"""

with open("app.py", "w") as f:
    f.write(app_code)

